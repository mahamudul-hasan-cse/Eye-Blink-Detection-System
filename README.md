# ğŸ¯ Eye Blink Detection System

**A real-time computer vision application that detects eye blinks and simulates Enter key presses â€” designed for accessibility, automation, and hands-free interaction.**

---

## ğŸ“Œ Overview

This project uses a webcam feed to detect human blinks using facial landmarks and Eye Aspect Ratio (EAR). When a blink is detected, it can simulate pressing the **Enter key**. This allows hands-free control of applications like Notepad, PowerPoint, and more.

Built with:
- **Python**
- **OpenCV**
- **dlib**
- **PyAutoGUI**
- **Tkinter (for GUI version)**

---

## ğŸ§  How It Works

1. **Face Detection** â€“ OpenCV Haar Cascade or Dlib HOG
2. **Eye Landmark Detection** â€“ Dlib's 68-point shape predictor
3. **EAR Calculation** â€“ Computes vertical/horizontal eye distances
4. **Blink Detection** â€“ If EAR falls below threshold for a number of frames
5. **Action** â€“ Simulates pressing Enter key using PyAutoGUI

### ğŸ‘ï¸ EAR Formula:

<img width="632" height="142" alt="blink_detection_equation" src="https://github.com/user-attachments/assets/2fd760cc-2942-4929-8cc4-d8b74b607e76" />

---

## ğŸ—‚ï¸ File Structure

<img width="614" height="386" alt="image" src="https://github.com/user-attachments/assets/5f43f2d2-5edf-4bfa-afef-8b15c150754d" />


## âš™ï¸ Features

### âœ… Detection
- Real-time video from webcam
- Face and eye detection using facial landmarks
- Eye Aspect Ratio (EAR) calculation
- Accurate blink detection using threshold and frame count

### ğŸ® Controls
| Key | Action |
|-----|--------|
| `q` | Quit application |
| `s` | Toggle Enter key simulation |
| `r` | Reset blink counter |
| `SPACE` | Manual Enter key test |

### ğŸ“Š Visual Feedback
- Live EAR value on screen
- Blink count on-screen and in console
- Face: blue rectangle, Eyes: green contours
- Console logs:  
[BLINK DETECTED] Enter key pressed.
---

## ğŸ–¥ï¸ Application Modes

### ğŸŸ¢ GUI Version (`gui_app.py`)
- Start/Stop buttons
- Sensitivity slider
- Activity log
- Toggle key simulation

### ğŸ”µ Command-Line Version (`main.py`)
- Lightweight
- Real-time console output
- Key shortcuts

### âšª Standalone Version (`working_blink_detector.py`)
- All-in-one script
- Fastest and most stable
- Ideal for demo

---

## ğŸ“¦ Requirements

- Python 3.11.9 (recommended)
- Webcam (internal or USB)
- Windows 10/11

### Python Libraries

Install everything with:

pip install -r requirements.txt

Or individually:
pip install opencv-python dlib imutils numpy pyautogui

ğŸš€ How to Run:
1. Activate Virtual Environment
cd path/to/project
.\venv\Scripts\activate

3. Run Any Version
GUI:
python gui_app.py

Command-line:
python main.py

Best All-in-One:
python working_blink_detector.py

Or double-click:
run_blink_detector.bat

ğŸ§ª Testing Instructions
Open Notepad or any text editor.

Run the program.

Blink normally in front of the webcam.

Observe:

Blink counter increasing

â€œEnter key pressedâ€ log in terminal

New lines in the editor when simulation is ON

ğŸ” Important Notes
The file shape_predictor_68_face_landmarks.dat is required for facial landmark detection but is too large for GitHub.
Download it from here:
ğŸ”— https://github.com/davisking/dlib-models/blob/master/shape_predictor_68_face_landmarks.dat.bz2

Extract it and place it in your project folder.

ğŸš« .gitignore (recommended)
gitignore
venv/*.dat*.pyc__pycache__/*.mp4.DS_Store

ğŸ“š Use Cases
â™¿ Accessibility: Help users control systems with eye blinks.
ğŸ“½ï¸ Presentations: Advance slides without hands.
ğŸ§ª HCI Projects: Use as a real-world input control prototype.
ğŸ•¹ï¸ Automation: Interact with software using eye movement.

ğŸ’¡ Tips
Ensure good lighting and position webcam at eye level.
Blink gently â€” system tracks both eyes.
Adjust the frame threshold or EAR sensitivity as needed.

ğŸ›¡ï¸ Safety Features
PyAutoGUI failsafe: Move your mouse to the top-left corner to immediately abort all automation.
Toggle simulation: Press 's' or use GUI checkbox.

ğŸ§‘â€ğŸ’» Author
This project was developed as part of a university Operating Systems course, with support from AI-based augmentation tools and research into computer vision and user input automation.
